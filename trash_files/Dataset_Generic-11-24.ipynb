{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "### Pulls pushshift data using PMAW api, visit https://github.com/mattpodolak/pmaw for docs and details\n",
    "### Running will make pull request, unneccessary and takes forever so only uncomment if need to make a new dataset. Work from csv instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of pulling a specified number of posts (aka submissions) from a subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:pmaw.PushshiftAPIBase:Not all PushShift shards are active. Query results may be incomplete.\n",
      "INFO:pmaw.PushshiftAPIBase:Total:: Success Rate: 100.00% - Requests: 20 - Batches: 2 - Items Remaining: 0\n"
     ]
    }
   ],
   "source": [
    "# Replace value for subreddit with desired subreddit name, case-sensitive\n",
    "# Replace value for limit to set desired number of submissions(posts) to pull\n",
    "# limit=None will pull all submissions(posts) from the subreddit\n",
    "# Beware, pulling all posts will take time, mem, cpu\n",
    "submissions = api.search_submissions(subreddit=\"disney\", limit=2000)\n",
    "\n",
    "sub_df = pd.DataFrame(submissions)\n",
    "\n",
    "# Rename path, leaving the rest of the parameters should be fine\n",
    "# sub_df.to_csv('./data/disney_500_subs.csv', header=True, index=False, columns=list(sub_df.axes[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clark/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0,1,4,5,6,8,9,10,11,12,16,18,19,20,21,22,24,25,26,27,28,29,30,31,35,37,39,43,44,45,49,53,56,58,59,60,61,62,65,66,67,68,71,73,74,75,77,78,79,80) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/disney_all_subs_w_dates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11527"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.selftext.isnull()\n",
    "\n",
    "df3 = df[df2 == False]\n",
    "\n",
    "df4 = df3[df3.selftext != \"[deleted]\"]\n",
    "\n",
    "df5 = df4[df4.selftext != \"[removed]\"]\n",
    "\n",
    "df6 = df5[df5.selftext != '']\n",
    "\n",
    "len(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df2 = sub_df.selftext.isnull()\n",
    "\n",
    "sub_df3 = sub_df[sub_df2 == False]\n",
    "\n",
    "sub_df4 = sub_df3[sub_df3.selftext != \"[deleted]\"]\n",
    "\n",
    "sub_df5 = sub_df4[sub_df4.selftext != \"[removed]\"]\n",
    "\n",
    "sub_df6 = sub_df5[sub_df5.selftext != '']\n",
    "\n",
    "len(sub_df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world where one of the most popular female marvel characters is completely green (Gamora). Why wasn't Angelina Jolie sporting the infamous green skin that the original character rocked so well.\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "My best guess, is that the actress herself just didn't want to put up with the makeup but I would love to hear a better theory\n",
      "It's weird how in Lilo and Stitch, when Jumba sits in his jail cell, reading the newspaper, there is a specific picture of Jumba with what looks like the movies's iconic version of guns aimed at him. \n",
      "\n",
      "It looks like the picture was taken when he was probably caught in the act of what looks like a Frankenstin creation with experiment 626, aka Stitch on a board and helmets and all that.\n",
      "\n",
      "That's weird because in the sequel, Stitch has a glitch, we see a full scene of Jumba creating Stitch and we see everything from the point where he created him to the intergalatical guards rushing in and taking them both away.\n",
      "\n",
      "That's weird. Right?\n",
      "Should Princess Aurora's dress be\n",
      "\n",
      "* Peasant dress\n",
      "* Pink\n",
      "* Blue\n",
      " \n",
      "\n",
      "I tried to sign up for Gold but it always redirects me back to the homepage with no errors. Anyone else?\n",
      "\n",
      "thx!\n",
      "Hi, who else of you loves Disney‚Äôs Fairy Tale Weddings? üíéüíç Share your experiences and how you got to know and love the show! ü¶ã It is absolutely amazing and beautiful to watch, I am a huge fan! üíô \n",
      "If there are any of you who maybe even participated in the show, I would love to hear your story and how the experience of filming your wedding was! üëó \n",
      "All the best! üíçüíé\n",
      "Considering that DC Comics originally made Ben 10 &amp; The Power Puff Girls, they are in the DC Universe even though they are produced from a different company for a different target audience. So, is there anything like that in the Marvel Universe (Any franchise that doesn't make you think of Marvel when you see it but is in the Marvel universe)\n",
      "So Maui in the your welcome song said ‚ÄúFor the islands I pulled from the sea‚Äù \n",
      "\n",
      "Ok so he pulled the islands up? \n",
      "\n",
      "Then how was he thrown in the ocean by his parents who the movie says was human?????\n",
      "\n",
      "I dunno this may be easily debunked but it‚Äôs been bothering me\n",
      "I was watching Baby Sloth Videos on YouTube (recommend btw cutest animal in the world) when the sound they used reminded me of Kevin the Bird from UP and I was wondering what animal/noise they actually used to make Kevin's sound. Any ideas?\n",
      "Looking to fly from MSY straight into Orlando and we‚Äôre trying to see if it‚Äôs necessary to have a car there? Or are there shuttles too and from airport that are easy to navigate? We haven‚Äôt booked a hotel yet either... but plan on staying as close as possible. (I‚Äôm a Disney amateur so please forgive)\n",
      "The Walt Disney Company will webcast its Investor Day 2020 on December 10, 2020. The event, focused on the Company‚Äôs direct-to-consumer streaming services, is scheduled to begin at approximately 4:30 p.m. ET / 1:30 p.m. PT. The Investor Day is expected to last approximately four hours.  \n",
      "\n",
      "[https://thewaltdisneycompany.com/disney-investor-day-2020/](https://thewaltdisneycompany.com/disney-investor-day-2020/) \n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "Please use this thread for all discussion relating to the Investor Day.\n",
      "&amp;#x200B;\n",
      "\n",
      "Hello Reddit World,\n",
      "\n",
      "This is my first ever post on this site and so naturally it MUST be important.\n",
      "\n",
      "For the past 3 years or more I have been searching for a book that lives in my memories but I am not sure what it is called. I always check the local used book store children's section amongst the stares of many confused children thinking to themselves \"why is this woman over here frantically searching through picture books\". Well, its just me, searching for a book that I cannot stop thinking about since I told my husband about how much that book meant to me.\n",
      "\n",
      "Now to get to the part where I tell you why this book means so much to me. Simple, my Nana (Great Grandmother) used to read it to me every single time I was at her house. One of my earliest memories in my life is sitting in my Nanas lap and her reading me THIS particular book.\n",
      "\n",
      "It was a book about Daisy and Minnie Mouse . Either one of them or both of them were getting together to make a lemonade stand to save money for something they wanted to buy. This is all I remember about the book other than the end of the book when they are counting the money they earned.\n",
      "\n",
      "I was born in 1992 so this book would have possibly came out around that time before or after.\n",
      "\n",
      "A friend of mine suggested I turn to all the smart people of Reddit to see if maybe someone knew what the book was named or maybe they had it tucked away in a dark corner of their attic. I have tried everything, I have messaged Disney directly in a desperate attempt, I even messaged some sellers on Ebay asking if the story in the books they were selling matched that story.\n",
      "\n",
      "Anyways, thank you in advance to anyone that might know what my crazy self is talking about. And maybe I can finally stop obsessing and find this book that has so much sentimental value.\n",
      "\n",
      "\\~ Alimoraa\n",
      "Hi All, I've just finished One Day at Disney (the series of shorts) and The Imagineering Story and was wondering if there were other good shows/documentaries about the parks? Or even shows that take place in WDW would be great.\n",
      "I recently discovered that \"Make Mine Music\" is the only Disney Animation Studios film that is not on Disney+. I find this to be baffling, does anyone know the reason for this?\n",
      "\n",
      "For those who have seen it, how is it? Out of the 58 films the studio has produced, this is one of the four I have not yet had a chance to see!\n",
      "This is kind of a weird question, but I couldn't think of a better place to post it. I'm trying to remember the name of a particular movie, but I don't remember much from it. All I know is that it's live-action, before the 2010's, maybe even before the 2000's, and there's a scene I remember fairly well.\n",
      "\n",
      "I should probably mention that I only remember the following scene from playing TONS of 2nd Edition Disney Scene It? with my family as a kid. Oddly specific, I know, but that might help narrow it down.\n",
      "\n",
      "There's a specific scene where a young boy (I think he's British?) is talking to his sister over breakfast and listing things off, but he listed them as \"A, 2, and D\" instead of \"1, 2, and 3\" or \"A, B, and C\". I also know for a fact it's not Mary Poppins, but there's a number of other live-action Disney movies that take place in Britain.\n",
      "\n",
      "Any help would be appreciated a lot. Thanks so much in advance, everyone!\n",
      "I've been trying to find a way to gift my girlfriend with a 1 year subscription, but nothing seems to allow me to do so, every time I see a link it leads me to a dismissed page, and there's nothing on the main website, only options for me to subscribe... Is there really no way to do such basic things? Gift cards are a no go for me, since I live in a small town with no Disney store and our local game stop doesn't sell them\n",
      "I just got back from a week-long trip to Disney World. During that week, every night when I got back to my Art of Animation room, I would fall asleep to an all night loop of the new Mickey Mouse Cartoon Shorts. I have to admit I paid zero attention to them before as I thought they were just another pre-schooler level of Disney cartoons or another safe bet with samey modern day animation that we see all the time now. \n",
      "\n",
      "After watching several episodes over the course of the week at Disney World, I have to say I am in love with this show! It is the type of Animation that I have been wanting to see make a comeback for a years. It is essentially Disney's own Spongebob or Ren and Stumpy (mainly the latter). It's classic Disney characters mixed with the edginess of classic Disney cartoons and the animated shows I grew up with in the early 2000's. In some aspects I am surprised and overjoyed that Disney allowed they're iconic characters to be put in these situations they find themselves in.\n",
      "\n",
      "Also every character has their time to shine and while Mickey is the star of the show, his supporting cast is no less impressive. Minnie surprised me the most as she was given so much to do. Locked in Love, Eau De Minnie, and The Birthday Song are just a small example of her best moments. Donald and Goofy steal the show everytime they show up. PotatoLand (the best episode) and Split Decision come to mind when I think great Goofy and Donald episodes. Donald is an absolute mood overall. Daisy is great to when she is given time to shine like in Two Can't Play and The Adorable Couple.\n",
      "\n",
      "What really shocked me was that if the episode featured countries such as China, Italy, Japan, France, Brazil, and so on, they would actually speak the language of that country for the entirety got the episode. That is such an amazing touch and really helps the show stand out big time.\n",
      "\n",
      "What got me as well was all the little Disney Easter Eggs such the Operatic Whale, the 50's dancers from Make Mine Music, Pinocchio, Cinderella, the Seven Dwarves, Night on Bald Mountain, etc. Such a nice touch to bring the rest of the Disney Universe into this utterly insane universe.\n",
      "\n",
      "So yes, those are my thoughts on the new Mickey Mouse shorts. I love these cartoons as it not only takes me back to the shows I use to watch as a kid but it also feels like it was made for both grown ups and adults. All ages can enjoy these because while kids will enjoy the characters and fast movements, adults will enjoy the brilliant animation, the masterful comedic timing, and the edgy insanity that ensues through each episode.\n",
      "\n",
      "\n",
      "Potato...LAAAAAAAAAAAAANNNND **Bonk**\n",
      "I am currently partaking in the Stitch Crashes event, plush only, but I am kind of upset I missed the Minnie Mouse Main Attraction event. Personally, I am indifferent to Minnie, but those were some great designs. Which movies do you guys think Stitch will crash after *Aladdin*? I think *Fantasia* will definitely be the last one. Also, I am thinking Pooh will be the next event.\n"
     ]
    }
   ],
   "source": [
    "for item in sub_df6.selftext:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deleted]\n",
      "nan\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "[deleted]\n",
      "[removed]\n",
      "\n",
      "[View Poll](https://www.reddit.com/poll/lc7u10)\n",
      "nan\n",
      "[deleted]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "[deleted]\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "nan\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "[deleted]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "[deleted]\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "\n",
      "[View Poll](https://www.reddit.com/poll/l36ofr)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[deleted]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "\n",
      "[View Poll](https://www.reddit.com/poll/l01x09)\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "[deleted]\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "[deleted]\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "[View Poll](https://www.reddit.com/poll/ms4hap)\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "[View Poll](https://www.reddit.com/poll/mfs4ch)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n",
      "[removed]\n",
      "\n",
      "\n",
      "[removed]\n",
      "\n",
      "\n",
      "\n",
      "[removed]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200, 400):\n",
    "    print(sub_df.iloc[i].selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n",
       "       'author_flair_type', 'author_fullname', 'author_patreon_flair',\n",
       "       'author_premium', 'awarders', 'can_mod_post', 'contest_mode',\n",
       "       'created_utc', 'domain', 'full_link', 'gildings', 'id',\n",
       "       'is_crosspostable', 'is_meta', 'is_original_content',\n",
       "       'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
       "       'link_flair_background_color', 'link_flair_richtext',\n",
       "       'link_flair_text_color', 'link_flair_type', 'locked', 'media_only',\n",
       "       'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n",
       "       'parent_whitelist_status', 'permalink', 'pinned', 'post_hint',\n",
       "       'preview', 'pwls', 'removed_by_category', 'retrieved_on', 'score',\n",
       "       'selftext', 'send_replies', 'spoiler', 'stickied', 'subreddit',\n",
       "       'subreddit_id', 'subreddit_subscribers', 'subreddit_type', 'thumbnail',\n",
       "       'thumbnail_height', 'thumbnail_width', 'title', 'total_awards_received',\n",
       "       'treatment_tags', 'upvote_ratio', 'url', 'url_overridden_by_dest',\n",
       "       'whitelist_status', 'wls', 'media', 'media_embed', 'secure_media',\n",
       "       'secure_media_embed', 'is_gallery', 'crosspost_parent',\n",
       "       'crosspost_parent_list', 'author_flair_background_color',\n",
       "       'author_flair_text_color', 'banned_by', 'gallery_data',\n",
       "       'media_metadata', 'is_created_from_ads_ui'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of pulling all posts (aka submissions) from a subreddit\n",
    "##### Beware, pulling all posts will take time, mem, cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_submissions = api.search_submissions(subreddit=\"Tesla\", limit=None)\n",
    "\n",
    "all_sub_df = pd.DataFrame(all_submissions)\n",
    "\n",
    "# Rename path, leave the rest of the parameters\n",
    "sub_df.to_csv('./data/disney_all_subs.csv', header=True, index=False, columns=list(sub_df.axes[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "### Download comments based on submissions pulled in above query. \n",
    "#### This code block will only the comments of the submissions queried above and saves to a csv. It takes much longer than simply pulling submissions\n",
    "\n",
    "###### Running will make pull request, unneccessary and takes forever so only uncomment if need to make a new dataset. Work from csv instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace path\n",
    "subs_df = pd.read_csv('./data/disney_500_subs.csv',header=0) \n",
    "\n",
    "sub_ids = list(subs_df.loc[:, 'id']) \n",
    "\n",
    "# retrieve comment ids for submissions\n",
    "comment_ids = api.search_submission_comment_ids(ids=sub_ids)\n",
    "comment_ids = list(comment_ids)\n",
    "\n",
    "# retrieve comments by id\n",
    "comments = api.search_comments(ids=comment_ids)\n",
    "\n",
    "comments_df = pd.DataFrame(comments)\n",
    "\n",
    "# Replace path\n",
    "comments_df.to_csv('./data/disney_500_comments.csv', header=True, index=False, columns=list(comments_df.axes[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to pull a given number of comments rather than just those from samples already queried (FASTER)\n",
    "#### This method is much faster and should be used for pulling a large number of comments or all comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()\n",
    "\n",
    "# Replace value for subreddit with desired subreddit name, case-sensitive\n",
    "comments = api.search_comments(subreddit=\"wallstreetbets\", limit=300000)\n",
    "\n",
    "comments_df = pd.DataFrame(comments)\n",
    "\n",
    "# Replace path\n",
    "comments_df.to_csv('./data/wallstreetbets_comments.csv', header=True, index=False, columns=list(comments_df.axes[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with submissions data, mainly adding a new date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View columns of dataset df\n",
    "sub_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-66bca1fb78df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Returns column of dates when submissions were created\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msub_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_utc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sub_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Returns column of dates when submissions were created\n",
    "# Times are UTC timezone and Unix in format\n",
    "sub_df.created_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single example of converting from Unix date-time to readable string date-time format\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "ts = sub_df.created_utc[0]\n",
    "print(ts)\n",
    "print(datetime.utcfromtimestamp(ts).strftime('%m-%d-%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list of all Unix times in readable string date-time format\n",
    "\n",
    "sub_dates = []\n",
    "\n",
    "for _ in sub_df['created_utc']:\n",
    "    fts = datetime.utcfromtimestamp(_).strftime('%m-%d-%Y')\n",
    "    sub_dates.append(fts)\n",
    "\n",
    "# Appends new column to dataframe, contains readable string date-times\n",
    "sub_df['creation_date'] = all_sub_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves dataset to csv\n",
    "# Replace path\n",
    "sub_df.to_csv('./data/disney_all_subs_w_dates.csv', header=True, index=False, columns=list(sub_df.axes[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with comments data, mainly adding a new dates column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_dates = []\n",
    "\n",
    "for _ in comments_df['created_utc']:\n",
    "    fts = datetime.utcfromtimestamp(_).strftime('%m-%d-%Y')\n",
    "    com_dates.append(fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['creation_date'] = com_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple plotting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.scatter(sub_df['creation_date'], sub_df['score'])\n",
    "plt.xticks(rotation=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_sub_df['creation_date'], all_sub_df['score'])\n",
    "plt.xticks(rotation=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
