{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae917c2b",
   "metadata": {},
   "source": [
    "# Clark Whitehead\n",
    "# Sentiment Analysis - LSTM\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7425f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2716b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/clark/anaconda3/lib/python3.8/site-packages (4.59.0)\n",
      "Requirement already satisfied: boto3 in /home/clark/anaconda3/lib/python3.8/site-packages (1.20.5)\n",
      "Requirement already satisfied: requests in /home/clark/anaconda3/lib/python3.8/site-packages (2.25.1)\n",
      "Requirement already satisfied: regex in /home/clark/anaconda3/lib/python3.8/site-packages (2021.4.4)\n",
      "Requirement already satisfied: sentencepiece in /home/clark/anaconda3/lib/python3.8/site-packages (0.1.96)\n",
      "Requirement already satisfied: sacremoses in /home/clark/anaconda3/lib/python3.8/site-packages (0.0.46)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/clark/anaconda3/lib/python3.8/site-packages (from boto3) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/clark/anaconda3/lib/python3.8/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.5 in /home/clark/anaconda3/lib/python3.8/site-packages (from boto3) (1.23.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/clark/anaconda3/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.5->boto3) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/clark/anaconda3/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.5->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/clark/anaconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.5->boto3) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clark/anaconda3/lib/python3.8/site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/clark/anaconda3/lib/python3.8/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/clark/anaconda3/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: joblib in /home/clark/anaconda3/lib/python3.8/site-packages (from sacremoses) (1.0.1)\n",
      "Requirement already satisfied: click in /home/clark/anaconda3/lib/python3.8/site-packages (from sacremoses) (7.1.2)\n",
      "Requirement already satisfied: tokenizers in /home/clark/anaconda3/lib/python3.8/site-packages (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub in /home/clark/anaconda3/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/clark/anaconda3/lib/python3.8/site-packages (from huggingface-hub) (20.9)\n",
      "Requirement already satisfied: filelock in /home/clark/anaconda3/lib/python3.8/site-packages (from huggingface-hub) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/clark/anaconda3/lib/python3.8/site-packages (from huggingface-hub) (3.7.4.3)\n",
      "Requirement already satisfied: requests in /home/clark/anaconda3/lib/python3.8/site-packages (from huggingface-hub) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /home/clark/anaconda3/lib/python3.8/site-packages (from huggingface-hub) (4.59.0)\n",
      "Requirement already satisfied: pyyaml in /home/clark/anaconda3/lib/python3.8/site-packages (from huggingface-hub) (5.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/clark/anaconda3/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/clark/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clark/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/clark/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clark/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/clark/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "# Requires extra packages.\n",
    "!pip install tqdm boto3 requests regex sentencepiece sacremoses\n",
    "!pip install tokenizers\n",
    "!pip install huggingface-hub\n",
    "import pickle\n",
    "import cloudpickle as cp\n",
    "import math\n",
    "import sklearn.metrics # Area Under the ROC calculations.\n",
    "import matplotlib.pylab as plt # Plotting\n",
    "from urllib.request import urlopen\n",
    "import torch\n",
    "#Downloads a tokenizer that will automatically convert words to indices in a big dictionary.\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045492a",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7a66f908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 7592, 2045, 999, 2129, 2024, 2017, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "tweet = \"Hello there! How are you?\"\n",
    "indexed_tokens = tokenizer.encode(tweet, padding='max_length', add_special_tokens=True) \n",
    "# Create transition matrix as sparse matrix to save memory.\n",
    "print(indexed_tokens[:50])\n",
    "n = tokenizer.vocab_size\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee650622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.decode(indexed_tokens, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb42474",
   "metadata": {},
   "source": [
    "# Store all 35k file titles in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1988a0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filesplit/reddit99917556.json',\n",
       " 'filesplit/reddit998757.json',\n",
       " 'filesplit/reddit997973.json',\n",
       " 'filesplit/reddit99922195.json',\n",
       " 'filesplit/reddit99909782.json',\n",
       " 'filesplit/reddit99912979.json',\n",
       " 'filesplit/reddit99905760.json',\n",
       " 'filesplit/reddit99911182.json',\n",
       " 'filesplit/reddit99900043.json',\n",
       " 'filesplit/reddit99903226.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "paths = [str(x) for x in Path('./filesplit/').glob('*.json')]\n",
    "paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef97fe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34119"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4fb0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to read\n",
    "# json file\n",
    " \n",
    "count = 0\n",
    "list1 = []\n",
    "\n",
    "matches = [\"xbox\", \"Xbox\", \"XBOX\"]\n",
    "# Opening JSON file\n",
    "for i in range(100):\n",
    "    f = open(paths[i], 'r')\n",
    "    data = [json.loads(line) for line in f]\n",
    "    for item in data:\n",
    "        if any(x in item[\"subreddit\"] for x in matches):\n",
    "            list1.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9afa61dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e86341d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DayzXbox'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1[2][\"subreddit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "032b26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for item in list1:\n",
    "    if item[\"selftext\"] != \"[removed]\":\n",
    "        list2.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e42c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9cdf17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As the title says, I have not owned an Xbox since the Xbox360, and after seeing the exclusives coming to this console, I had to get my hands on one. Last week Walmart had a drop, and I scored a series X, this console is fantastic, the ultimate gamepass is a game changer. I own a ps5 as well, and I am truly excited for this generation of gaming.\\n\\nLooking forward to joining the Xbox community online, I don’t have many friends on there, hopefully change that soon. The Bethesda exclusives, Halo, Forza, and gamepass ultimate made me realize I was being one dimensional on my console preferences. \\n\\nI must say Gears 5 looks fantastic on my 65” OLED. \\n\\nTo everyone still trying for a console, be patient, you will get one I promise!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list2[0][\"selftext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aedeee45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1[6][\"selftext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0850b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e05d2ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deleted]\n"
     ]
    }
   ],
   "source": [
    "# for item in data:\n",
    "#     if \"made\" in item:\n",
    "#         print(\"yes\")\n",
    "\n",
    "print(data[102][\"selftext\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "013690ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if \"hey\" in data[102][\"selftext\"]:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228b894",
   "metadata": {},
   "source": [
    "# Load sentiment analysis training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b153eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9af78a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c46cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af1ff573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     family mormon have never tried explain them t...\n",
       "1    buddhism has very much lot compatible with chr...\n",
       "2    seriously don say thing first all they won get...\n",
       "3    what you have learned yours and only yours wha...\n",
       "4    for your own benefit you may want read living ...\n",
       "5    you should all sit down together and watch the...\n",
       "6     was teens when discovered zen meditation was ...\n",
       "7                             jesus was zen meets jew \n",
       "8    there are two varieties christians dogmatic th...\n",
       "9    dont worry about trying explain yourself just ...\n",
       "Name: clean_comment, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0de424c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37249"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3417539e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buddhism has very much lot compatible with christianity especially considering that sin and suffering are almost the same thing suffering caused wanting things shouldn want going about getting things the wrong way christian this would mean wanting things that don coincide with god will and wanting things that coincide but without the aid jesus buddhism could also seen proof god all mighty will and omnipotence certainly christians are lucky have one such christ there side but what about everyone else well many christians believe god grace salvation and buddhism god way showing grace upon others would also help study the things jesus said and see how buddha has made similar claims such rich man getting into heaven joke basically advocating that should rid ourselves material possessions fact distinctly remembered jesus making someone cry because that someone asked what achieve salvation and jesus replied with live like buddhist very very roughly translated also point out that buddha rarely spoke anything about god theory personally because knew well enough leave that jesus and mohamed who came later just remember conflict difference opinion but education can fun involving and enlightening easier teach something than prove right like intelligent design '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a734f",
   "metadata": {},
   "source": [
    "# Remove all null from X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0c96efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = X.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73d24b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X[P == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6da59fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     family mormon have never tried explain them t...\n",
       "1    buddhism has very much lot compatible with chr...\n",
       "2    seriously don say thing first all they won get...\n",
       "3    what you have learned yours and only yours wha...\n",
       "4    for your own benefit you may want read living ...\n",
       "5    you should all sit down together and watch the...\n",
       "6     was teens when discovered zen meditation was ...\n",
       "7                             jesus was zen meets jew \n",
       "8    there are two varieties christians dogmatic th...\n",
       "9    dont worry about trying explain yourself just ...\n",
       "Name: clean_comment, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b918846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee9119de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[P == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f442e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2   -1\n",
       "3    0\n",
       "4    1\n",
       "5   -1\n",
       "6    1\n",
       "7    0\n",
       "8   -1\n",
       "9    1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235845e",
   "metadata": {},
   "source": [
    "# Remove all strings longer than 512 words and their matching Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06fcc3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a3c29a65a14c88aba85eae11c75b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55961ace3a654e65afe70d89314935e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37016 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allSamples = []\n",
    "with tqdm(total=len(X)) as pbar:\n",
    "    for i in range(len(X)):\n",
    "        indexed_tokens = tokenizer.encode(X.iloc[i], padding='max_length', add_special_tokens=True) \n",
    "        allSamples.append(np.array(indexed_tokens))\n",
    "        pbar.update(1)\n",
    "            \n",
    "listRemove = []\n",
    "count = 0\n",
    "for item in allSamples:\n",
    "    if len(item) > 512:\n",
    "        listRemove.append(count)\n",
    "    count += 1\n",
    "    \n",
    "allSamples = []\n",
    "with tqdm(total=37016) as pbar:\n",
    "    for i in range(len(X)):\n",
    "        if i not in listRemove:\n",
    "            indexed_tokens = tokenizer.encode(X.iloc[i], padding='max_length', add_special_tokens=True) \n",
    "            allSamples.append(np.array(indexed_tokens))\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c44a6a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37149"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4aa026e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.drop(Y.index[listRemove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1aa53aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37016"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d018ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allSamples[914])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a22f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listRemove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea346791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37016"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0aa873f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8e965e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(allSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a288ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2155</td>\n",
       "      <td>15111</td>\n",
       "      <td>2031</td>\n",
       "      <td>2196</td>\n",
       "      <td>2699</td>\n",
       "      <td>4863</td>\n",
       "      <td>2068</td>\n",
       "      <td>2027</td>\n",
       "      <td>2145</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>11388</td>\n",
       "      <td>2038</td>\n",
       "      <td>2200</td>\n",
       "      <td>2172</td>\n",
       "      <td>2843</td>\n",
       "      <td>11892</td>\n",
       "      <td>2007</td>\n",
       "      <td>7988</td>\n",
       "      <td>2926</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>5667</td>\n",
       "      <td>2123</td>\n",
       "      <td>2360</td>\n",
       "      <td>2518</td>\n",
       "      <td>2034</td>\n",
       "      <td>2035</td>\n",
       "      <td>2027</td>\n",
       "      <td>2180</td>\n",
       "      <td>2131</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>2054</td>\n",
       "      <td>2017</td>\n",
       "      <td>2031</td>\n",
       "      <td>4342</td>\n",
       "      <td>6737</td>\n",
       "      <td>1998</td>\n",
       "      <td>2069</td>\n",
       "      <td>6737</td>\n",
       "      <td>2054</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>2005</td>\n",
       "      <td>2115</td>\n",
       "      <td>2219</td>\n",
       "      <td>5770</td>\n",
       "      <td>2017</td>\n",
       "      <td>2089</td>\n",
       "      <td>2215</td>\n",
       "      <td>3191</td>\n",
       "      <td>2542</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101</td>\n",
       "      <td>2017</td>\n",
       "      <td>2323</td>\n",
       "      <td>2035</td>\n",
       "      <td>4133</td>\n",
       "      <td>2091</td>\n",
       "      <td>2362</td>\n",
       "      <td>1998</td>\n",
       "      <td>3422</td>\n",
       "      <td>1996</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101</td>\n",
       "      <td>2001</td>\n",
       "      <td>13496</td>\n",
       "      <td>2043</td>\n",
       "      <td>3603</td>\n",
       "      <td>16729</td>\n",
       "      <td>13804</td>\n",
       "      <td>2001</td>\n",
       "      <td>2059</td>\n",
       "      <td>6151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101</td>\n",
       "      <td>4441</td>\n",
       "      <td>2001</td>\n",
       "      <td>16729</td>\n",
       "      <td>6010</td>\n",
       "      <td>16522</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101</td>\n",
       "      <td>2045</td>\n",
       "      <td>2024</td>\n",
       "      <td>2048</td>\n",
       "      <td>9903</td>\n",
       "      <td>8135</td>\n",
       "      <td>3899</td>\n",
       "      <td>12644</td>\n",
       "      <td>2008</td>\n",
       "      <td>23120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101</td>\n",
       "      <td>2123</td>\n",
       "      <td>2102</td>\n",
       "      <td>4737</td>\n",
       "      <td>2055</td>\n",
       "      <td>2667</td>\n",
       "      <td>4863</td>\n",
       "      <td>4426</td>\n",
       "      <td>2074</td>\n",
       "      <td>19960</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3     4      5      6      7     8      9    ...  502  \\\n",
       "0  101   2155  15111   2031  2196   2699   4863   2068  2027   2145  ...    0   \n",
       "1  101  11388   2038   2200  2172   2843  11892   2007  7988   2926  ...    0   \n",
       "2  101   5667   2123   2360  2518   2034   2035   2027  2180   2131  ...    0   \n",
       "3  101   2054   2017   2031  4342   6737   1998   2069  6737   2054  ...    0   \n",
       "4  101   2005   2115   2219  5770   2017   2089   2215  3191   2542  ...    0   \n",
       "5  101   2017   2323   2035  4133   2091   2362   1998  3422   1996  ...    0   \n",
       "6  101   2001  13496   2043  3603  16729  13804   2001  2059   6151  ...    0   \n",
       "7  101   4441   2001  16729  6010  16522    102      0     0      0  ...    0   \n",
       "8  101   2045   2024   2048  9903   8135   3899  12644  2008  23120  ...    0   \n",
       "9  101   2123   2102   4737  2055   2667   4863   4426  2074  19960  ...    0   \n",
       "\n",
       "   503  504  505  506  507  508  509  510  511  \n",
       "0    0    0    0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0    0    0  \n",
       "5    0    0    0    0    0    0    0    0    0  \n",
       "6    0    0    0    0    0    0    0    0    0  \n",
       "7    0    0    0    0    0    0    0    0    0  \n",
       "8    0    0    0    0    0    0    0    0    0  \n",
       "9    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[10 rows x 512 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d35657",
   "metadata": {},
   "source": [
    "# Normalize (scale) data for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de1dbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaler = MinMaxScaler(feature_range=(0, 1)) # scale so that all the X data will range from 0 to 1\n",
    "Xscaler.fit(df)\n",
    "scaled_X = Xscaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f56afed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "41e76d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = j.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f72605d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37016, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50209388",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yscaler = MinMaxScaler(feature_range=(0, 1)) # scale so that all the X data will range from 0 to 1\n",
    "Yscaler.fit(j)\n",
    "scaled_Y = Yscaler.transform(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ddb5907e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. ],\n",
       "       [1. ],\n",
       "       [0. ],\n",
       "       [0.5],\n",
       "       [1. ],\n",
       "       [0. ],\n",
       "       [1. ],\n",
       "       [0.5],\n",
       "       [0. ],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_Y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "206f11b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37016, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4545bd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37016, 512)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "671a432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "...     scaled_X, scaled_Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cabf2cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3a06abff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.06659659, 0.14368977, 0.29301182, 0.18925203,\n",
       "       0.68345705, 0.30724388, 0.11063309, 0.11635918, 0.0665054 ,\n",
       "       0.10411149, 0.10222266, 0.06995462, 0.06788918, 0.10391914,\n",
       "       0.08183005, 0.06680501, 0.11420428, 0.06719211, 0.06611242,\n",
       "       0.20015899, 0.06730291, 0.09620035, 0.07380661, 0.07303334,\n",
       "       0.26705956, 0.0672873 , 0.06606428, 0.45551248, 0.00337625])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da4f07c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24800, 512)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c813f16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24800, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70afb82",
   "metadata": {},
   "source": [
    "# Transform data to timeseries for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ba7e2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TimeseriesGenerator(x_train, y_train, length=25, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9d550d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.sequence.TimeseriesGenerator"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2935ca9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.        , 0.40564918, 0.070305  , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06659659, 0.14368977, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.2046387 , 0.19846342, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.0646977 , 0.07745803, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.07273405, 0.88147829, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.09331661, 0.11679968, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.06659659, 0.14368977, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.2046387 , 0.19846342, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06680004, 0.23085075, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.07273405, 0.88147829, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.09331661, 0.11679968, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06910583, 0.06609928, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.2046387 , 0.19846342, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06680004, 0.23085075, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.25974026, 0.61168328, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.09331661, 0.11679968, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06910583, 0.06609928, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.14462039, 0.07434513, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.        , 0.57010613, 0.06861609, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.43406463, 0.07755737, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.0905361 , 0.07017253, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.23146045, 0.15657184, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.50269574, 0.06831804, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06588451, 0.06712587, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.43406463, 0.07755737, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.0905361 , 0.07017253, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06520633, 0.12319105, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.50269574, 0.06831804, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06588451, 0.06712587, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.32820182, 0.11593867, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.0905361 , 0.07017253, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06520633, 0.12319105, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.07215761, 0.06679471, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.06588451, 0.06712587, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.32820182, 0.11593867, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.06591842, 0.06765573, ..., 0.        ,\n",
       "          0.        , 0.        ]]]),\n",
       " array([[0. ],\n",
       "        [0.5],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0. ],\n",
       "        [0.5],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [0.5],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0.5],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [1. ]]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1c42ac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 25, 512)\n"
     ]
    }
   ],
   "source": [
    "print(generator[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5e08a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clark/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "<ipython-input-128-c7a6b7c3dce1>:42: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "248/248 [==============================] - 47s 183ms/step - loss: 0.3125 - accuracy: 0.4232\n",
      "Epoch 2/3\n",
      "248/248 [==============================] - 45s 183ms/step - loss: 0.3125 - accuracy: 0.4232\n",
      "Epoch 3/3\n",
      "248/248 [==============================] - 46s 184ms/step - loss: 0.3125 - accuracy: 0.4232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f39b839a220>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM#, CuDNNLSTM\n",
    "\n",
    "\n",
    "# mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
    "# (x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test\n",
    "\n",
    "# x_train = x_train/255.0\n",
    "# x_test = x_test/255.0\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(x_train[0].shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# IF you are running with a GPU, try out the CuDNNLSTM layer type instead (don't pass an activation, tanh is required)\n",
    "model.add(LSTM(512, input_shape=(25,512), activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit_generator(generator,\n",
    "          epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
