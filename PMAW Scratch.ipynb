{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (0,1,4,5,6,8,9,10,11,12,16,18,19,20,21,22,24,25,26,27,28,29,30,31,35,37,39,43,44,49,53,56,58,59,60,65,66,67,68,69,74,75,76,77,78,79,80,81,83,85,87,88,89,90,91,92,93,94,95) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "yfinance = pd.read_csv(\"data/disney_yfinance.csv\")\n",
    "dis_submissions = pd.read_csv(\"data/disney_all_sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2000</td>\n",
       "      <td>28.855125</td>\n",
       "      <td>29.533344</td>\n",
       "      <td>28.361876</td>\n",
       "      <td>29.471687</td>\n",
       "      <td>23.115255</td>\n",
       "      <td>8402230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2000</td>\n",
       "      <td>29.594999</td>\n",
       "      <td>31.444689</td>\n",
       "      <td>29.594999</td>\n",
       "      <td>31.198063</td>\n",
       "      <td>24.469284</td>\n",
       "      <td>16051191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2000</td>\n",
       "      <td>31.198063</td>\n",
       "      <td>32.677814</td>\n",
       "      <td>31.198063</td>\n",
       "      <td>32.492844</td>\n",
       "      <td>25.484806</td>\n",
       "      <td>19823822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2000</td>\n",
       "      <td>32.492844</td>\n",
       "      <td>32.677814</td>\n",
       "      <td>31.198063</td>\n",
       "      <td>31.198063</td>\n",
       "      <td>24.469284</td>\n",
       "      <td>7903193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2000</td>\n",
       "      <td>31.198063</td>\n",
       "      <td>31.691313</td>\n",
       "      <td>30.396530</td>\n",
       "      <td>30.704813</td>\n",
       "      <td>24.082420</td>\n",
       "      <td>6773543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  1/3/2000  28.855125  29.533344  28.361876  29.471687  23.115255   8402230\n",
       "1  1/4/2000  29.594999  31.444689  29.594999  31.198063  24.469284  16051191\n",
       "2  1/5/2000  31.198063  32.677814  31.198063  32.492844  25.484806  19823822\n",
       "3  1/6/2000  32.492844  32.677814  31.198063  31.198063  24.469284   7903193\n",
       "4  1/7/2000  31.198063  31.691313  30.396530  30.704813  24.082420   6773543"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfinance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_safe</th>\n",
       "      <th>rte_mode</th>\n",
       "      <th>author_id</th>\n",
       "      <th>previous_visits</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>view_count</th>\n",
       "      <th>creation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>The-Remix-God-ALT</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_8b0yo2pg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Supershlee777</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_7zle95u7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>theagileartist</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_7ohoma2p</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>PeachyLeee</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_684v8y3b</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01-10-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>artsychimichanga</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_50qxngv9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01-10-2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings allow_live_comments             author author_flair_css_class  \\\n",
       "0            []               False  The-Remix-God-ALT                      0   \n",
       "1            []               False      Supershlee777                      0   \n",
       "2            []               False     theagileartist                      0   \n",
       "3            []               False         PeachyLeee                      0   \n",
       "4            []               False   artsychimichanga                      0   \n",
       "\n",
       "  author_flair_richtext author_flair_text author_flair_type author_fullname  \\\n",
       "0                    []                 0              text     t2_8b0yo2pg   \n",
       "1                    []                 0              text     t2_7zle95u7   \n",
       "2                    []                 0              text     t2_7ohoma2p   \n",
       "3                    []                 0              text     t2_684v8y3b   \n",
       "4                    []                 0              text     t2_50qxngv9   \n",
       "\n",
       "  author_patreon_flair author_premium  ... brand_safe rte_mode author_id  \\\n",
       "0                False          False  ...          0        0         0   \n",
       "1                False          False  ...          0        0         0   \n",
       "2                False          False  ...          0        0         0   \n",
       "3                False          False  ...          0        0         0   \n",
       "4                False          False  ...          0        0         0   \n",
       "\n",
       "   previous_visits suggested_sort author_created_utc approved_at_utc  \\\n",
       "0                0              0                0.0               0   \n",
       "1                0              0                0.0               0   \n",
       "2                0              0                0.0               0   \n",
       "3                0              0                0.0               0   \n",
       "4                0              0                0.0               0   \n",
       "\n",
       "  banned_at_utc view_count creation_date  \n",
       "0             0          0    01-10-2021  \n",
       "1             0          0    01-10-2021  \n",
       "2             0          0    01-10-2021  \n",
       "3             0          0    01-10-2021  \n",
       "4             0          0    01-10-2021  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n",
       "       'author_flair_type', 'author_fullname', 'author_patreon_flair',\n",
       "       'author_premium',\n",
       "       ...\n",
       "       'brand_safe', 'rte_mode', 'author_id', 'previous_visits',\n",
       "       'suggested_sort', 'author_created_utc', 'approved_at_utc',\n",
       "       'banned_at_utc', 'view_count', 'creation_date'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_submissions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allow_live_comments', 'author', 'author_fullname', 'awarders',\n",
       "       'created_utc', 'domain', 'full_link', 'id', 'is_self', 'is_video',\n",
       "       'link_flair_richtext', 'link_flair_type', 'num_comments',\n",
       "       'num_crossposts', 'over_18', 'pinned', 'retrieved_on', 'score',\n",
       "       'selftext', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'subreddit_subscribers', 'subreddit_type', 'thumbnail', 'title',\n",
       "       'total_awards_received', 'treatment_tags', 'upvote_ratio',\n",
       "       'link_flair_text', 'media', 'media_embed', 'distinguished',\n",
       "       'is_created_from_ads_ui', 'gallery_data', 'media_metadata',\n",
       "       'crosspost_parent', 'crosspost_parent_list', 'gilded',\n",
       "       'steward_reports', 'updated_utc', 'collections', 'og_description',\n",
       "       'og_title', 'removed_by', 'brand_safe', 'rte_mode', 'author_id',\n",
       "       'previous_visits', 'suggested_sort', 'author_created_utc',\n",
       "       'approved_at_utc', 'banned_at_utc', 'view_count', 'creation_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = [\n",
    "    'all_awardings', 'author_flair_css_class', 'author_flair_richtext', 'author_patreon_flair', 'author_premium',\n",
    "    'can_mod_post', 'contest_mode', 'gildings', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', \n",
    "    'is_robot_indexable', 'link_flair_background_color', 'link_flair_text_color', 'locked', 'media_only', 'no_follow',\n",
    "    'parent_whitelist_status', 'permalink', 'pwls', 'removed_by_category', 'send_replies', 'spoiler',\n",
    "    'url', 'whitelist_status', 'wls', 'link_flair_css_class', 'link_flair_template_id', 'post_hint', 'preview',\n",
    "    'thumbnail_height', 'thumbnail_width', 'url_overridden_by_dest', 'author_flair_background_color', 'author_flair_template_id',\n",
    "    'author_flair_text_color', 'is_gallery', 'edited', 'banned_by', 'author_is_blocked', 'author_flair_text', 'author_flair_type',\n",
    "    'secure_media', 'secure_media_embed', 'author_cakeday'\n",
    "]\n",
    "\n",
    "for _ in drop_columns:\n",
    "    del dis_submissions[_]\n",
    "        \n",
    "dis_submissions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "80255    0\n",
       "80256    3\n",
       "80257    0\n",
       "80258    0\n",
       "80259    3\n",
       "Name: num_comments, Length: 80260, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_submissions['num_comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1610296640\n",
       "1        1610295828\n",
       "2        1610294416\n",
       "3        1610293394\n",
       "4        1610292454\n",
       "            ...    \n",
       "80255    1417798928\n",
       "80256    1417798765\n",
       "80257    1417795991\n",
       "80258    1417790770\n",
       "80259    1417789646\n",
       "Name: created_utc, Length: 80260, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_submissions['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sub_dates = []\n",
    "\n",
    "for _ in dis_submissions['created_utc']:\n",
    "    fts = datetime.utcfromtimestamp(_).strftime('%m-%d-%Y')\n",
    "    sub_dates.append(fts)\n",
    "\n",
    "# Appends new column to dataframe, contains readable string date-times\n",
    "dis_submissions['creation_date'] = sub_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        01-10-2021\n",
       "1        01-10-2021\n",
       "2        01-10-2021\n",
       "3        01-10-2021\n",
       "4        01-10-2021\n",
       "            ...    \n",
       "80255    12-05-2014\n",
       "80256    12-05-2014\n",
       "80257    12-05-2014\n",
       "80258    12-05-2014\n",
       "80259    12-05-2014\n",
       "Name: creation_date, Length: 80260, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_submissions['creation_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to append a readable creation date column to subreddit df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_reddit(reddit_df):\n",
    "    sub_dates = []\n",
    "\n",
    "    for _ in reddit_df['created_utc']:\n",
    "        fts = datetime.utcfromtimestamp(_).strftime('%m-%d-%Y')\n",
    "        sub_dates.append(fts)\n",
    "\n",
    "    # Appends new column to dataframe, contains readable string date-times\n",
    "    reddit_df['creation_date'] = sub_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-05-2014'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_begin = dis_submissions['creation_date'].iloc[-1]\n",
    "dis_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis_datetime_object = datetime.strptime(dis_begin, '%m-%d-%Y')\n",
    "# dis_datetime_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/3/2000'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_begin = yfinance['Date'][0]\n",
    "y_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_datetime_object = datetime.strptime(y_begin, '%m/%d/%Y')\n",
    "# y_datetime_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yfinance['Date'][0].replace('/', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "\n",
    "# for _ in yfinance['Date']:\n",
    "#     y_datetime_object = datetime.strptime(_, '%m/%d/%Y')\n",
    "#     if y_datetime_object == dis_datetime_object:\n",
    "#         print(y_datetime_object)\n",
    "#         print(i)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yfinance['Date'][3755]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Created parsed dates columns for yfinance dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dates = []\n",
    "\n",
    "def yfi_parsed_dates(df):\n",
    "    for _ in df['Date']:\n",
    "        y_datetime_object = datetime.strptime(_, '%m/%d/%Y')\n",
    "        parsed_dates.append(y_datetime_object)\n",
    "    df['parsed_dates'] = parsed_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This version below handles different datetime formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def yfi_parsed_dates(df):\n",
    "#     parsed_dates = []\n",
    "\n",
    "#     for _ in df['Date']:\n",
    "#         if '-' in _:\n",
    "#             y_datetime_object = datetime.strptime(_, '%Y-%m-%d')\n",
    "            \n",
    "#         elif '/' in _:\n",
    "#             y_datetime_object = datetime.strptime(_, '%m/%d/%Y')\n",
    "    \n",
    "#         parsed_dates.append(y_datetime_object)\n",
    "    \n",
    "#     df['parsed_dates'] = parsed_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfi_parsed_dates(yfinance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2000-01-03 00:00:00')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfinance['parsed_dates'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Created parsed dates columns for subreddit dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dates = []\n",
    "\n",
    "def red_parsed_dates(df):\n",
    "    for _ in df['creation_date']:\n",
    "        red_datetime_object = datetime.strptime(_, '%m-%d-%Y')\n",
    "        parsed_dates.append(red_datetime_object)\n",
    "    df['parsed_dates'] = parsed_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_parsed_dates(dis_submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-01-10 00:00:00')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_submissions['parsed_dates'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations to only use yfinance dates in range of subreddit post dates and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80259   2014-12-05\n",
       "80258   2014-12-05\n",
       "80248   2014-12-05\n",
       "80250   2014-12-05\n",
       "80251   2014-12-05\n",
       "           ...    \n",
       "904     2021-12-04\n",
       "903     2021-12-04\n",
       "902     2021-12-04\n",
       "901     2021-12-04\n",
       "900     2021-12-04\n",
       "Name: parsed_dates, Length: 80260, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_submissions['parsed_dates'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2000-01-03\n",
       "1      2000-01-04\n",
       "2      2000-01-05\n",
       "3      2000-01-06\n",
       "4      2000-01-07\n",
       "          ...    \n",
       "5488   2021-10-25\n",
       "5489   2021-10-26\n",
       "5490   2021-10-27\n",
       "5491   2021-10-28\n",
       "5492   2021-10-29\n",
       "Name: parsed_dates, Length: 5493, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfinance['parsed_dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-12-05 00:00:00\n",
      "2021-10-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "reddit_begin = dis_submissions['parsed_dates'].iloc[-1]\n",
    "yahoo_end = yfinance['parsed_dates'].iloc[-1]\n",
    "\n",
    "print(reddit_begin)\n",
    "print(yahoo_end)\n",
    "\n",
    "# dis_submissions = dis_submissions[(dis_submissions['parsed_dates'] <= yahoo_end)]\n",
    "# yfinance = yfinance[(yfinance['parsed_dates'] >= reddit_begin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     reddit_begin = reddit_df['parsed_dates'].iloc[-1]\n",
    "#     reddit_end = reddit_df['parsed_dates'].sort_values().iloc[0]\n",
    "#     yahoo_end = yfinance_df['parsed_dates'].iloc[-1]\n",
    "    \n",
    "#     reddit_df = reddit_df[(reddit_df['parsed_dates'] <= yahoo_end)]\n",
    "#     yfinance_df = yfinance_df[(yfinance_df['parsed_dates'] <= reddit_end)]\n",
    "#     yfinance_df = yfinance_df[(yfinance_df['parsed_dates'] >= reddit_begin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_date_range(yfinance_df, reddit_df):\n",
    "\n",
    "    reddit_begin = reddit_df['parsed_dates'].iloc[-1]\n",
    "    yahoo_end = yfinance_df['parsed_dates'].iloc[-1]\n",
    "    \n",
    "    reddit_df = reddit_df[(reddit_df['parsed_dates'] <= yahoo_end)]    \n",
    "    yfinance_df = yfinance_df[(yfinance_df['parsed_dates'] >= reddit_begin)]\n",
    "\n",
    "    return(yfinance_df, reddit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfinance = match_date_range(yfinance, dis_submissions)[0]\n",
    "dis_submissions = match_date_range(yfinance, dis_submissions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80259   2014-12-05\n",
       "80248   2014-12-05\n",
       "80249   2014-12-05\n",
       "80250   2014-12-05\n",
       "80251   2014-12-05\n",
       "           ...    \n",
       "813     2021-10-29\n",
       "812     2021-10-29\n",
       "811     2021-10-29\n",
       "821     2021-10-29\n",
       "800     2021-10-29\n",
       "Name: parsed_dates, Length: 78872, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_submissions['parsed_dates'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3755   2014-12-05\n",
       "3756   2014-12-08\n",
       "3757   2014-12-09\n",
       "3758   2014-12-10\n",
       "3759   2014-12-11\n",
       "          ...    \n",
       "5488   2021-10-25\n",
       "5489   2021-10-26\n",
       "5490   2021-10-27\n",
       "5491   2021-10-28\n",
       "5492   2021-10-29\n",
       "Name: parsed_dates, Length: 1738, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfinance['parsed_dates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group together desired values with same dates in subreddit df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_sub_scores = dis_submissions[['num_comments', 'score', 'parsed_dates']]\n",
    "reddit_sub_scores.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_date_grouped = reddit_sub_scores.groupby(reddit_sub_scores['parsed_dates'].dt.date, as_index=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_date_grouped['parsed_dates'] = scores_date_grouped.index\n",
    "scores_date_grouped_df = scores_date_grouped.set_index(np.arange(len(scores_date_grouped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_date_grouped_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for _ in np.arange(len(scores_date_grouped_df)):\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "#         i += 1\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_arr = []\n",
    "# for _ in np.arange(len(scores_date_grouped_df)):\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 5 or scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 6:\n",
    "#         i_arr.append(scores_date_grouped_df.iloc[_]['parsed_dates'])\n",
    "    \n",
    "# len(i_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekends = 0\n",
    "# i = 0\n",
    "# k = 0\n",
    "# weekend_sum = []\n",
    "# weekender = []\n",
    "\n",
    "\n",
    "# for _ in np.arange(len(scores_date_grouped_df)):\n",
    "\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 5:\n",
    "#         weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 6:\n",
    "#         weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "#         weekender.append(weekends)\n",
    "\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 0:\n",
    "#         monday = scores_date_grouped_df.iloc[_]['score'] + weekender[i]\n",
    "\n",
    "#         scores_date_grouped_df.iloc[_]['score'] = monday\n",
    "#         i += 1\n",
    "\n",
    "#         weekends = 0\n",
    "        \n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "#         weekend_sum.append(scores_date_grouped_df.iloc[_]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekend_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(weekend_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def group_weekend_metrics(scores_date_grouped_df):\n",
    "#     weekends = 0\n",
    "#     i = 0\n",
    "#     k = 0\n",
    "#     weekend_dict = {}\n",
    "#     weekender = []\n",
    "\n",
    "#     for _ in np.arange(len(scores_date_grouped_df)):\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "#             weekend_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = 0\n",
    "\n",
    "\n",
    "#     for _ in np.arange(len(scores_date_grouped_df)):\n",
    "\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 5:\n",
    "#             weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 6:\n",
    "#             weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "#             weekender.append(weekends)\n",
    "\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 0:\n",
    "#             monday = scores_date_grouped_df.iloc[_]['score'] + weekender[i]\n",
    "\n",
    "#             scores_date_grouped_df.iloc[_]['score'] = monday\n",
    "#             i += 1\n",
    "\n",
    "#             weekends = 0\n",
    "\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "#             weekend_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = (scores_date_grouped_df.iloc[_]['score'])\n",
    "            \n",
    "#     return weekend_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_weekend_metrics(scores_date_grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def group_weekend_metrics(scores_date_grouped_df):\n",
    "#     weekends = 0\n",
    "#     weekends_coms = 0\n",
    "#     i = 0\n",
    "#     k = 0\n",
    "#     weekend_dict = {}\n",
    "#     weekend_coms_dict = {}\n",
    "#     weekender = []\n",
    "#     weekender_coms = []\n",
    "#     dicts = []\n",
    "\n",
    "#     for _ in np.arange(len(scores_date_grouped_df)):\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "#             weekend_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = 0\n",
    "#             weekend_coms_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = 0\n",
    "\n",
    "\n",
    "#     for _ in np.arange(len(scores_date_grouped_df)):\n",
    "\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 5:\n",
    "#             weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "#             weekends_coms += scores_date_grouped_df.iloc[_]['num_comments']\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 6:\n",
    "#             weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "#             weekends_coms += scores_date_grouped_df.iloc[_]['num_comments']\n",
    "#             weekender.append(weekends)\n",
    "#             weekender_coms.append(weekends_coms)\n",
    "#             print(weekender_coms)\n",
    "\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 0:\n",
    "#             monday = scores_date_grouped_df.iloc[_]['score'] + weekender[i]\n",
    "#             monday_coms = scores_date_grouped_df.iloc[_]['num_comments'] + weekender_coms[i]\n",
    "\n",
    "#             scores_date_grouped_df.loc[scores_date_grouped_df.index[_], 'score'] = monday\n",
    "#             scores_date_grouped_df.loc[scores_date_grouped_df.index[_], 'num_comments'] = monday_coms\n",
    "#             i += 1\n",
    "        \n",
    "#             weekends = 0\n",
    "#             weekends_coms = 0\n",
    "            \n",
    "#             monday = 0\n",
    "#             monday_coms = 0\n",
    "\n",
    "\n",
    "#         if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "#             weekend_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = (scores_date_grouped_df.iloc[_]['score'])\n",
    "#             weekend_coms_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = (scores_date_grouped_df.iloc[_]['num_comments'])\n",
    "    \n",
    "#     dicts.append(weekend_dict)\n",
    "#     dicts.append(weekend_coms_dict)\n",
    "    \n",
    "#     return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_weekend_metrics(scores_date_grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekend_dict = group_weekend_metrics(scores_date_grouped_df)[0]\n",
    "# weekend_coms_dict = group_weekend_metrics(scores_date_grouped_df)[1]\n",
    "\n",
    "# weekend_dict == weekend_coms_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekends = 0\n",
    "# weekends_coms = 0\n",
    "# i = 0\n",
    "# k = 0\n",
    "# # weekend_sum = []\n",
    "# weekend_dict = {}\n",
    "# weekend_coms_dict = {}\n",
    "# weekender = []\n",
    "# weekender_coms = []\n",
    "\n",
    "# for _ in np.arange(len(scores_date_grouped_df)):\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "#         weekend_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = 0\n",
    "#         weekend_coms_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = 0\n",
    "\n",
    "\n",
    "# for _ in np.arange(len(scores_date_grouped_df)):\n",
    "\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 5:\n",
    "#         weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "#         weekends_coms += scores_date_grouped_df.iloc[_]['num_comments']\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 6:\n",
    "#         weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "#         weekends_coms += scores_date_grouped_df.iloc[_]['num_comments']\n",
    "#         weekender.append(weekends)\n",
    "#         weekender_coms.append(weekends_coms)\n",
    "\n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 0:\n",
    "#         monday = scores_date_grouped_df.iloc[_]['score'] + weekender[i]\n",
    "#         monday_coms = scores_date_grouped_df.iloc[_]['num_comments'] + weekender_coms[i]\n",
    "\n",
    "#         scores_date_grouped_df.loc[scores_date_grouped_df.index[_], 'score'] = monday\n",
    "#         scores_date_grouped_df.loc[scores_date_grouped_df.index[_], 'num_comments'] = monday_coms\n",
    "#         i += 1\n",
    "\n",
    "#         weekends = 0\n",
    "#         weekends_coms = 0\n",
    "        \n",
    "#     if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "#         weekend_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = (scores_date_grouped_df.iloc[_]['score'])\n",
    "#         weekend_coms_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = (scores_date_grouped_df.iloc[_]['num_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_weekend_metrics(scores_date_grouped_df):\n",
    "    weekends = 0\n",
    "    weekends_coms = 0\n",
    "    i = 0\n",
    "    k = 0\n",
    "    weekend_dict = {}\n",
    "    weekend_coms_dict = {}\n",
    "    weekender = []\n",
    "    weekender_coms = []\n",
    "    dict_arr = []\n",
    "\n",
    "    for _ in np.arange(len(scores_date_grouped_df)):\n",
    "        if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "            weekend_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = 0\n",
    "            weekend_coms_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = 0\n",
    "\n",
    "\n",
    "    for _ in np.arange(len(scores_date_grouped_df)):\n",
    "\n",
    "        if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 5:\n",
    "            weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "            weekends_coms += scores_date_grouped_df.iloc[_]['num_comments']\n",
    "            \n",
    "        if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 6:\n",
    "            weekends += scores_date_grouped_df.iloc[_]['score']\n",
    "            weekends_coms += scores_date_grouped_df.iloc[_]['num_comments']\n",
    "            weekender.append(weekends)\n",
    "            weekender_coms.append(weekends_coms)\n",
    "\n",
    "        if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() == 0:\n",
    "            monday = scores_date_grouped_df.iloc[_]['score'] + weekender[i]\n",
    "            monday_coms = scores_date_grouped_df.iloc[_]['num_comments'] + weekender_coms[i]\n",
    "\n",
    "            scores_date_grouped_df.loc[scores_date_grouped_df.index[_], 'score'] = monday\n",
    "            scores_date_grouped_df.loc[scores_date_grouped_df.index[_], 'num_comments'] = monday_coms\n",
    "            i += 1\n",
    "\n",
    "            weekends = 0\n",
    "            weekends_coms = 0\n",
    "\n",
    "        if scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() !=  5 and scores_date_grouped_df.iloc[_]['parsed_dates'].weekday() != 6:\n",
    "            weekend_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = (scores_date_grouped_df.iloc[_]['score'])\n",
    "            weekend_coms_dict[scores_date_grouped_df.iloc[_]['parsed_dates']] = (scores_date_grouped_df.iloc[_]['num_comments'])\n",
    "            \n",
    "            \n",
    "            dict_arr.append(weekend_dict)\n",
    "            dict_arr.append(weekend_coms_dict)\n",
    "            \n",
    "    df = pd.DataFrame(np.arange(len(weekend_dict)))\n",
    "    df['parsed_dates'] = weekend_dict.keys()\n",
    "    df['score'] = weekend_dict.values()\n",
    "    df['num_comments'] = weekend_coms_dict.values()\n",
    "    df.drop(columns=0, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_weekend_metrics(scores_date_grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_arr = group_weekend_metrics(scores_date_grouped_df)\n",
    "\n",
    "# weekend_score_dict = result_arr[0]\n",
    "# weekend_coms_dict = result_arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_score_com_df(score_dict, coms_dict):\n",
    "#     df = pd.DataFrame(np.arange(len(score_dict)))\n",
    "#     df['parsed_dates'] = score_dict.keys()\n",
    "#     df['score'] = score_dict.values()\n",
    "#     df['num_comments'] = coms_dict.values()\n",
    "#     df.drop(columns=0, inplace=True)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_df = group_weekend_metrics(scores_date_grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday_df = make_score_com_df(weekend_score_dict, weekend_coms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday_df = pd.DataFrame(np.arange(len(weekend_dict)))\n",
    "# weekday_df['parsed_dates'] = weekend_dict.keys()\n",
    "# weekday_df['score'] = weekend_dict.values()\n",
    "# weekday_df['num_comments'] = weekend_coms_dict.values()\n",
    "# weekday_df.drop(columns=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weekday_df) == len(yfinance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_dates(yfinance_df, reddit_df):\n",
    "    yfi_dates = list(yfinance_df['parsed_dates'])\n",
    "    reddit_dates = list(reddit_df['parsed_dates'])\n",
    "\n",
    "    drop_it_red = []\n",
    "    drop_it_yfi = []\n",
    "\n",
    "    i = 0\n",
    "    k = 0\n",
    "\n",
    "    for _ in np.arange(len(reddit_df)):\n",
    "        if reddit_df.iloc[_]['parsed_dates'] not in yfi_dates:\n",
    "            drop_it_red.append(i)\n",
    "        i += 1\n",
    "\n",
    "    reddit_df.drop(reddit_df.index[drop_it_red], inplace=True)\n",
    "\n",
    "    for _ in np.arange(len(yfinance_df)):\n",
    "        if yfinance_df.iloc[_]['parsed_dates'] not in reddit_dates:\n",
    "            drop_it_yfi.append(k)\n",
    "        k += 1\n",
    "\n",
    "    yfinance_df.drop(yfinance_df.index[drop_it_yfi], inplace=True)\n",
    "    \n",
    "    return(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dates(yfinance, weekday_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listy = list(yfinance['parsed_dates'])\n",
    "# listy_2 = list(weekday_df['parsed_dates'])\n",
    "\n",
    "# drop_it_red = []\n",
    "# drop_it_yfi = []\n",
    "\n",
    "# i = 0\n",
    "# k = 0\n",
    "\n",
    "# for _ in np.arange(len(weekday_df)):\n",
    "#     if weekday_df.iloc[_]['parsed_dates'] not in listy:\n",
    "#         drop_it_red.append(i)\n",
    "#     i += 1\n",
    "        \n",
    "# weekday_df.drop(weekday_df.index[drop_it_red], inplace=True)\n",
    "\n",
    "# for _ in np.arange(len(yfinance)):\n",
    "#     if yfinance.iloc[_]['parsed_dates'] not in listy_2:\n",
    "#         drop_it_yfi.append(k)\n",
    "#     k += 1\n",
    "\n",
    "# yfinance.drop(yfinance.index[drop_it_yfi], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weekday_df) == len(yfinance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticker plot of Dis prices from 12/05/2014 to 12/05/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.plot(yfinance['parsed_dates'], yfinance['Close'])\n",
    "plt.title(\"DIS Ticker\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Closing Price (USD)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.scatter(weekday_df['parsed_dates'], weekday_df['score'])\n",
    "plt.xticks(rotation=270)\n",
    "plt.title(\"Reddit Submission Scores\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.scatter(weekday_df['parsed_dates'], weekday_df['num_comments'])\n",
    "plt.xticks(rotation=270)\n",
    "plt.title(\"Reddit Post # of Comments\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"# of Comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_score = weekday_df['score']\n",
    "X_coms = weekday_df['num_comments']\n",
    "y = yfinance['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "linreg_score = linregress(weekday_df['score'], yfinance['Close'])\n",
    "print(f\"Linear regression of stock prices as function of subreddit post scores: \\n{linreg_score}\\n\")\n",
    "\n",
    "linreg_coms = linregress(weekday_df['num_comments'], yfinance['Close'])\n",
    "print(f\"Linear regression of stock prices as function of number of comments on subreddit posts: \\n{linreg_coms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear regression of stock prices as function of subreddit post scores\")\n",
    "print(f\"The slope is: {linreg_score.slope}\")\n",
    "print(f\"The Interecept is: {linreg_score.intercept}\")\n",
    "print(f\"The p.value is: {linreg_score.pvalue}\\n\")\n",
    "\n",
    "print(\"Linear regression of stock prices as function of number of comments on subreddit posts\")\n",
    "print(f\"The slope is: {linreg_coms.slope}\")\n",
    "print(f\"The Interecept is: {linreg_coms.intercept}\")\n",
    "print(f\"The p.value is: {linreg_coms.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,8))\n",
    "\n",
    "x_axis = x_axis = range(0, 20000)\n",
    "y_line = linreg_score.intercept + linreg_score.slope * x_axis\n",
    "\n",
    "plt.scatter(X_score, y)\n",
    "\n",
    "plt.plot(x_axis, y_line, color='red', linewidth=4, alpha=0.5)\n",
    "plt.title(\"Scores and DIS\")\n",
    "plt.xlabel(\"Reddit Post Scores\")\n",
    "plt.ylabel(\"Stock Prices ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,8))\n",
    "\n",
    "x_axis = x_axis = range(0, 2000)\n",
    "y_line = linreg_coms.intercept + linreg_coms.slope * x_axis\n",
    "\n",
    "plt.scatter(X_coms, y)\n",
    "\n",
    "plt.plot(x_axis, y_line, color='red', linewidth=4, alpha=0.5)\n",
    "plt.title(\"# of Comments and DIS\")\n",
    "plt.xlabel(\"Reddit Post # of Comments\")\n",
    "plt.ylabel(\"Stock Prices ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
